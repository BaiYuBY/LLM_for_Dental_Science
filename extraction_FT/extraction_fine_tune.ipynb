{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import bitsandbytes\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "import jsonlines\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_file = './all.jsonl'\n",
    "all_data = []\n",
    "with open(all_file, 'r', encoding='utf-8') as file:\n",
    "    for item in jsonlines.Reader(file):\n",
    "        all_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3dfa8b76214760ae747fcd81182f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_formats(data):\n",
    "    converted_data = []\n",
    "    entity_id_to_name = {}\n",
    "    entity_name_to_type = {}\n",
    "    for doc in data:\n",
    "        temp = {}\n",
    "        temp['id'] = doc['id']\n",
    "        temp['test'] = doc['text']\n",
    "        temp_total = []\n",
    "        temp_entity = []\n",
    "        temp_realtion = []\n",
    "\n",
    "        for e in doc['entities']:\n",
    "            identifier_name = e['id']\n",
    "            type_name = e['label']\n",
    "            start_point = e['start_offset']\n",
    "            end_point = e['end_offset']\n",
    "            temp_entity.append({\n",
    "                'id_name': identifier_name,\n",
    "                'type_name': type_name,\n",
    "                'start_offset': start_point,\n",
    "                'end_offset': end_point\n",
    "            })\n",
    "        for re_test in doc['relations']:\n",
    "            id_name = re_test['id']\n",
    "            from_id = re_test['from_id']\n",
    "            to_id = re_test['to_id']\n",
    "            relation_type = re_test['type']\n",
    "            temp_realtion.append({\n",
    "                'id_name': id_name,\n",
    "                'type_name': relation_type,\n",
    "                'from_id': from_id,\n",
    "                'to_id': to_id\n",
    "            })\n",
    "        temp['entity_list'] = temp_entity\n",
    "        temp['relation_list'] = temp_realtion\n",
    "        converted_data.append(temp)\n",
    "    return {\n",
    "        'data': converted_data\n",
    "    }\n",
    "\n",
    "def combine_text(data):\n",
    "    test_list = []\n",
    "    total_entity_list = []\n",
    "    total_relation_list = []\n",
    "    for m in data:\n",
    "        temp_test = m['test']\n",
    "        temp_entities = []\n",
    "        temp_relations = []\n",
    "        entity_list = m['entity_list']\n",
    "        relation_list = m['relation_list']\n",
    "        id_to_name = {}\n",
    "        name_to_type = {}\n",
    "\n",
    "        if entity_list == [] or entity_list == {} or entity_list == '' or entity_list == None:\n",
    "            temp_entities.append({\n",
    "                'id_name': '',\n",
    "                'type_name': '',\n",
    "                'test_name': ''\n",
    "            })\n",
    "        else:\n",
    "            for n in entity_list:\n",
    "                temp_entities.append({\n",
    "                    'id_name': n['id_name'],\n",
    "                    'type_name': n['type_name'],\n",
    "                    'test_name': temp_test[n['start_offset']:n['end_offset']]\n",
    "                })\n",
    "                id_to_name[n['id_name']] = temp_test[n['start_offset']:n['end_offset']]\n",
    "                name_to_type[temp_test[n['start_offset']:n['end_offset']]]= n['type_name']\n",
    "        total_entity_list.append(temp_entities)\n",
    "        test_list.append({\n",
    "            'id': m['id'],\n",
    "            'test': '\\n'.join(temp_test.split('\\n')[1::])\n",
    "        })\n",
    "\n",
    "        if relation_list == [] or relation_list == {} or relation_list == '' or relation_list == None:\n",
    "            temp_relations.append({\n",
    "                'id_name': '',\n",
    "                'type_name': '',\n",
    "                'entity1_name': '',\n",
    "                'entity1_type': '',\n",
    "                'entity2_name': '',\n",
    "                'entity2_type': ''\n",
    "            })\n",
    "        else:\n",
    "            for r in relation_list:\n",
    "                temp_relations.append({\n",
    "                    'id_name': r['id_name'],\n",
    "                    'type_name': r['type_name'],\n",
    "                    'entity1_name': id_to_name[r['from_id']],\n",
    "                    'entity1_type': name_to_type[id_to_name[r['from_id']]],\n",
    "                    'entity2_name': id_to_name[r['to_id']],\n",
    "                    'entity2_type': name_to_type[id_to_name[r['to_id']]]\n",
    "                })\n",
    "        total_relation_list.append(temp_relations)\n",
    "    return {\n",
    "        'test_list': test_list, \n",
    "        'total_entity_list': total_entity_list, \n",
    "        'total_relation_list': total_relation_list\n",
    "    }\n",
    "\n",
    "def load_model_and_tokenizer():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        './models/Llama3-Med42-8B',\n",
    "        device_map={\"\":0},\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('./models/Llama3-Med42-8B')\n",
    "    # tokenizer.pad_token = tokenizer.eos_token\n",
    "    return model, tokenizer\n",
    "model, tokenizer = load_model_and_tokenizer()\n",
    "\n",
    "def find_max_prompt_tokens(dataset, tokenizer):\n",
    "    # Initialize variables to keep track of the maximum tokens and the corresponding prompt\n",
    "    max_tokens = 0\n",
    "    max_prompt = \"\"\n",
    "\n",
    "    # Iterate over the dataset and tokenize the prompt\n",
    "    for data in dataset:\n",
    "        prompt = data['prompt']\n",
    "        tokens = tokenizer.encode(prompt)\n",
    "        token_count = len(tokens)\n",
    "\n",
    "        # Update max_tokens and max_prompt if the current one is longer\n",
    "        if token_count > max_tokens:\n",
    "            max_tokens = token_count\n",
    "            max_prompt = prompt\n",
    "\n",
    "    return max_tokens, max_prompt\n",
    "\n",
    "def prompt_generation(test_list, total_entity_list, total_relation_list):\n",
    "    dataset = []\n",
    "    global_entity_labels = []\n",
    "    global_relation_labels = []\n",
    "\n",
    "    for e in total_entity_list:\n",
    "        for ee in e:\n",
    "            if ee['type_name'] != '':\n",
    "                global_entity_labels.append(ee['type_name'])\n",
    "    for r in total_relation_list:\n",
    "        for rr in r:\n",
    "            if rr['type_name'] != '':\n",
    "                global_relation_labels.append(rr['type_name'])\n",
    "    global_entity_labels = list(set(global_entity_labels))\n",
    "    global_relation_labels = list(set(global_relation_labels))\n",
    "\n",
    "    INSTRUCTION = 'Identify the entities in the sentence and the relationships between them.'\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    The following is an unstructured question, please extract the relationship between the possible entities in the text, and the output should follow the following format: {'relation_type': 'test_relation', 'Entity1_name': 'test1_name', 'Entity1_type': 'test1_type', 'Entity2_name': 'test2_name', 'Entity2_type': 'test2_type}\n",
    "    You can only use the following entity types and relation types:\n",
    "        All entity types are: {clinical manifestations, materials, medication information, description, instrument, dosage, symptom, disease, prevention, oral part, causes, population, medicine, treatment, frequency, usage, examination} (seperated by ,)\n",
    "        All relationship types are: {medicine_contraindicates_population, treatment_has_description, is, medicine_contraindication_disease, disease_caused_disease, symptom_has_description, medicine_side-effect_symptom, medication-information_frequency, disease_usually happens_population, disease_has_clinical manifestations, clinical manifestations_happens at_oral part, Causes_disease, population_use_as_alternative_medicine, symptom_oralpart, clinical manifestations_use_treatment, examination_has_description, symptom_cause_symptom, medicine_medication-information, disease_has_description, oral_part_discription, examination_at_oral part, medicine_side-effect_disease, disease_symptom, disease_oral-part, disease_examination, prevent, disease_treatment, medicine_has_description, disease_lack response_examination, treatment_frequency, medicine_reduce_symptom, materials_use_as_medicine, instrument_discription, parent-child, medicine_treats_disease, clinical manifestations_from_examination, materials_has_description} (seperated by ,)\n",
    "    Only extract the entities and relation that related with dental medical. Some relation type identify the two entity types that it connects, like medicine_contraindication_disease connect medicine and disease. Please make sure that relationship types like the above are connected to the correct entity types. If anything is related to the picture or illustration that do not appear in the input text, please ignore it.\n",
    "    \"\"\".strip().strip('\\n')\n",
    "    for i in range(len(test_list)):\n",
    "        output = []\n",
    "        for r in total_relation_list[i]:\n",
    "            output.append(str({\n",
    "                'relation_type': r['type_name'], \n",
    "                'Entity1_name': r['entity1_name'], \n",
    "                'Entity1_type': r['entity1_type'], \n",
    "                'Entity2_name': r['entity2_name'], \n",
    "                'Entity2_type': r['entity2_type']\n",
    "            }))\n",
    "        dataset.append({\n",
    "            'input': test_list[i]['test'],\n",
    "            'output': f\"{', '.join(output)}\",\n",
    "            'prompt': '### Instruction: \\n' + INSTRUCTION + '\\n' + SYSTEM_PROMPT + \\\n",
    "            '\\n\\n### Input: \\n' + test_list[i]['test'] + '\\n\\n### Response:'\n",
    "        })\n",
    "    with open('test.txt', 'w') as f:\n",
    "        for i in dataset:\n",
    "            f.write(str(i['prompt']) + str(i['output']) + '\\n')\n",
    "        f.write(str(find_max_prompt_tokens(dataset, tokenizer)))\n",
    "    return Dataset.from_pandas(pd.DataFrame(data=dataset))\n",
    "\n",
    "def print_trainable_parameterss(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': prompt_generation(**combine_text(**convert_formats(all_data)))\n",
    "}).shuffle(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acd147b9b1245afb53db5b72ff8de11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
       " '_load_in_8bit': False,\n",
       " '_load_in_4bit': True,\n",
       " 'llm_int8_threshold': 6.0,\n",
       " 'llm_int8_skip_modules': None,\n",
       " 'llm_int8_enable_fp32_cpu_offload': False,\n",
       " 'llm_int8_has_fp16_weight': False,\n",
       " 'bnb_4bit_quant_type': 'nf4',\n",
       " 'bnb_4bit_use_double_quant': True,\n",
       " 'bnb_4bit_compute_dtype': 'float16',\n",
       " 'bnb_4bit_quant_storage': 'uint8',\n",
       " 'load_in_4bit': True,\n",
       " 'load_in_8bit': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer()\n",
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"dense\"],\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 37,748,736 || all params: 8,068,009,984 || trainable%: 0.4679\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"./results\"\n",
    "per_device_train_batch_size = 1\n",
    "gradient_accumulation_steps = 2\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_steps = 30\n",
    "num_train_epochs = 4\n",
    "logging_steps = 1\n",
    "lr_scheduler_kwargs = {\n",
    "    'num_cycles': 5\n",
    "    }\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 1500\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    lr_scheduler_kwargs = lr_scheduler_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/root/miniconda3/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016e45df6e964f12aa73cdb5dde019a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/402 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset['train'],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lora_config = LoraConfig.from_pretrained('outputs')\n",
    "lora_config = LoraConfig.from_pretrained('/root/autodl-tmp/results/checkpoint-1500')\n",
    "test_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relation_type': 'treatment_has_description', 'Entity1_name': 'Flare-ups', 'Entity1_type': 'disease', 'Entity2_name': 'complete cleaning and shaping of canals, placement of intracanal medicament, and prescription of analgesic', 'Entity2_type': 'treatment'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"### Instruction: \n",
    "Identify the entities in the sentence and the relationships between them.\n",
    "The following is an unstructured question, please extract the relationship between the possible entities in the text, and the output should follow the following format: {'relation_type': 'test_relation', 'Entity1_name': 'test1_name', 'Entity1_type': 'test1_type', 'Entity2_name': 'test2_name', 'Entity2_type': 'test2_type}\n",
    "You can only use the following entity types and relation types:\n",
    "    All entity types are: {clinical manifestations, materials, description, instrument, dosage, symptom, disease, prevention, oral part, causes, population, medicine, treatment, frequency, usage, examination} (seperated by ,)\n",
    "    All relationship types are: {medicine_contraindicates_population, treatment_has_description, is, medicine_contraindication_disease, disease_caused_disease, symptom_has_description, medicine_side-effect_symptom, medication-information_frequency, disease_usually happens_population, disease_has_clinical manifestations, clinical manifestations_happens at_oral part, Causes_disease, population_use_as_alternative_medicine, symptom_oralpart, clinical manifestations_use_treatment, examination_has_description, symptom_cause_symptom, medicine_medication-information, disease_has_description, oral_part_discription, examination_at_oral part, medicine_side-effect_disease, disease_symptom, disease_oral-part, disease_examination, prevent, disease_treatment, medicine_has_description, disease_lack response_examination, treatment_frequency, medicine_reduce_symptom, materials_use_as_medicine, instrument_discription, parent-child, medicine_treats_disease, clinical manifestations_from_examination, materials_has_description} (seperated by ,)\n",
    "Only extract the entities and relation that related with patient inquiry dental medical. Some relation type identify the two entity types that it connects, like medicine_contraindication_disease connect medicine and disease. Please make sure that relationship types like the above are connected to the correct entity types and the entities name cannot be the same as the entities type. If anything is related to the picture or illustration that do not appear in the input text, please ignore it.\n",
    "### Input: \n",
    "\n",
    "# Flare-ups\n",
    "\n",
    "a. This is a true emergency and is so severe pat an unscheduled visit and treatment is required.\n",
    "b. A history of preoperative pain or swelling is pe best predictor of “flare-up” emergencies.\n",
    "c. No relationship exists between flare-ups and treatment procedures (i.e., single or multiple visits).\n",
    "d. Treatment generally involves complete cleaning and shaping of canals, placement of intracanal medicament, and prescription of analgesic.\n",
    "\n",
    "# Sterilization and Asepsis\n",
    "\n",
    "# Rationale for sterilization\n",
    "\n",
    "1. Endodontic instruments are contaminated with blood, soft and hard tissue remnants, bacteria, and bacterial by-products.\n",
    "2. Instruments must be cleaned often and disinfected during the procedure and sterilized afterward.\n",
    "3. Because instruments may be contaminated when new, they must be sterilized before initial use.\n",
    "\n",
    "# Types of sterilization\n",
    "\n",
    "1. Glutaraldehyde.\n",
    "2. Pressure sterilization.\n",
    "3. Dry heat sterilization.\n",
    "# C. Disinfection\n",
    "\n",
    "1. Surface disinfection during canal débridement is accomplished by using a sponge soaked in 70% isopropyl alcohol or proprietary quaternary ammonium solutions.\n",
    "\n",
    "2. Files can be thrust briskly in and out of this sponge to dislodge debris and contact the disinfectant.\n",
    "\n",
    "3. This procedure cleans but does not disinfect instruments.\n",
    "\n",
    "# 2.5 Radiographic Techniques\n",
    "\n",
    "# A. Diagnostic radiographs\n",
    "\n",
    "1. Angulation\n",
    "\n",
    "a. Paralleling technique—the most accurate radiographs are made using a paralleling technique.\n",
    "\n",
    "### Response: \n",
    "\"\"\"\n",
    "\n",
    "device = \"cuda:0\"\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\").to(device)\n",
    "outputs = test_model.generate(**inputs, max_new_tokens=2000)\n",
    "response = \"}\".join(tokenizer.decode(outputs[0], skip_special_tokens=True).split('\\n### Response: ')[-1].strip().split('}')[:-1:]) + '}'\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "with open(\"output.jsonl\", \"a\") as file:\n",
    "    dict_data = ast.literal_eval(response)\n",
    "    json_line = json.dumps(dict_data)\n",
    "    file.write(json_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
